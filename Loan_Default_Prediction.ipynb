{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "VKoUgwGY92TU",
    "outputId": "c7ff5613-b204-4ed3-feff-76cb107a98fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-a8ea5344-81f9-440a-b066-2ed63b5132d1\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-a8ea5344-81f9-440a-b066-2ed63b5132d1\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Loan_default.csv to Loan_default (1).csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNAQxGXP-mou"
   },
   "source": [
    "Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLlzHpJD-oBg",
    "outputId": "13114d1b-536b-4c82-ffc5-41b2a5e1c413"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3380730027.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "/tmp/ipython-input-3380730027.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, data shape: (255347, 18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('Loan_default.csv')\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols = ['Age', 'Income', 'LoanAmount', 'CreditScore',\n",
    "                'MonthsEmployed', 'NumCreditLines', 'InterestRate',\n",
    "                'LoanTerm', 'DTIRatio']\n",
    "\n",
    "categorical_cols = ['Education', 'EmploymentType', 'MaritalStatus',\n",
    "                    'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner']\n",
    "\n",
    "# Impute missing numeric columns with median\n",
    "for col in numeric_cols:\n",
    "    data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "# Impute missing categorical columns with mode\n",
    "for col in categorical_cols:\n",
    "    data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "\n",
    "# Drop duplicate rows\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "print(f\"After cleaning, data shape: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEUSr5uQ-wtf"
   },
   "source": [
    "Feature Selection and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9rcY9k3Q-o7Q",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "effe3e91-1103-42b8-8587-900e285e8f1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-12137387.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].map(binary_map)\n",
      "/tmp/ipython-input-12137387.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].map(binary_map)\n",
      "/tmp/ipython-input-12137387.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = X[col].map(binary_map)\n",
      "/tmp/ipython-input-12137387.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col])\n",
      "/tmp/ipython-input-12137387.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col])\n",
      "/tmp/ipython-input-12137387.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col])\n",
      "/tmp/ipython-input-12137387.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[col] = le.fit_transform(X[col])\n",
      "/tmp/ipython-input-12137387.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "target_col = 'Default'\n",
    "features = numeric_cols + categorical_cols\n",
    "\n",
    "X = data[features]\n",
    "y = data[target_col]\n",
    "\n",
    "# Map binary categorical to 0/1\n",
    "binary_map = {'Yes': 1, 'No': 0}\n",
    "for col in ['HasMortgage', 'HasDependents', 'HasCoSigner']:\n",
    "    X[col] = X[col].map(binary_map)\n",
    "\n",
    "# Label encode multi-class categorical features\n",
    "for col in ['Education', 'EmploymentType', 'MaritalStatus', 'LoanPurpose']:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Standard scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aholRa_p_e_A"
   },
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "69zAyCmf-2W0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z--91DSf_jCS"
   },
   "source": [
    "Handle Imbalance Data Using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJrOtSyb_gqT",
    "outputId": "0dd482d4-16c1-4a90-9930-3bddbfb9076d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      " Default\n",
      "0    180555\n",
      "1     23722\n",
      "Name: count, dtype: int64\n",
      "Class distribution after SMOTE:\n",
      " Default\n",
      "0    180555\n",
      "1    180555\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution before SMOTE:\\n\", y_train.value_counts())\n",
    "print(\"Class distribution after SMOTE:\\n\", pd.Series(y_train_res).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaGxs8wbCRKn"
   },
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RTgbjo48CTiz"
   },
   "outputs": [],
   "source": [
    "# Create interaction feature Income * CreditScore\n",
    "X_train_res['Income_CreditScore'] = X_train_res['Income'] * X_train_res['CreditScore']\n",
    "X_test['Income_CreditScore'] = X_test['Income'] * X_test['CreditScore']\n",
    "\n",
    "# Scale the new feature\n",
    "X_train_res['Income_CreditScore'] = scaler.fit_transform(X_train_res[['Income_CreditScore']])\n",
    "X_test['Income_CreditScore'] = scaler.transform(X_test[['Income_CreditScore']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3ibTxOW_rMM"
   },
   "source": [
    "Train Baseline Models & Evaluate with Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "weYQDy-F_lZn",
    "outputId": "3b6e6960-fbce-447b-c693-a3cf26ebdb98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Model: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.59      0.73     45139\n",
      "           1       0.19      0.74      0.30      5931\n",
      "\n",
      "    accuracy                           0.61     51070\n",
      "   macro avg       0.57      0.66      0.52     51070\n",
      "weighted avg       0.86      0.61      0.68     51070\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26615 18524]\n",
      " [ 1543  4388]]\n",
      "ROC AUC: 0.7319\n",
      "============================================================\n",
      "Training Random Forest...\n",
      "Model: RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.87     45139\n",
      "           1       0.25      0.48      0.33      5931\n",
      "\n",
      "    accuracy                           0.78     51070\n",
      "   macro avg       0.59      0.65      0.60     51070\n",
      "weighted avg       0.85      0.78      0.80     51070\n",
      "\n",
      "Confusion Matrix:\n",
      " [[36780  8359]\n",
      " [ 3073  2858]]\n",
      "ROC AUC: 0.7258\n",
      "============================================================\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:24:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92     45139\n",
      "           1       0.34      0.31      0.32      5931\n",
      "\n",
      "    accuracy                           0.85     51070\n",
      "   macro avg       0.62      0.61      0.62     51070\n",
      "weighted avg       0.84      0.85      0.85     51070\n",
      "\n",
      "Confusion Matrix:\n",
      " [[41589  3550]\n",
      " [ 4121  1810]]\n",
      "ROC AUC: 0.7310\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, threshold=0.4):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        y_prob = model.decision_function(X_test)\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=150, class_weight='balanced', random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    evaluate_model(model, X_test, y_test, threshold=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEFxQAjuDWTe"
   },
   "source": [
    "Model Comparison And Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nA3SRzl8_tQE",
    "outputId": "b83568f0-f9e9-4c6e-bc3b-9dd4a38a09f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Precision    Recall  F1-Score   ROC AUC\n",
      "0  Logistic Regression   0.191515  0.739842  0.304268  0.731859\n",
      "1        Random Forest   0.254792  0.481875  0.333333  0.725783\n",
      "2              XGBoost   0.337687  0.305176  0.320609  0.731021\n",
      "Selected best model for tuning: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def model_comparison(models, X_test, y_test, threshold=0.4):\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        results.append({'Model': name, 'Precision': precision, 'Recall': recall, 'F1-Score': f1, 'ROC AUC': roc_auc})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "comparison_df = model_comparison(models, X_test, y_test)\n",
    "print(comparison_df)\n",
    "\n",
    "# Select best model based on business priority, e.g., highest recall or F1-score\n",
    "best_model_name = comparison_df.sort_values(by='Recall', ascending=False).iloc[0]['Model']\n",
    "print(f\"Selected best model for tuning: {best_model_name}\")\n",
    "\n",
    "best_model = models[best_model_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJHU55qMGOct"
   },
   "source": [
    "Hyperparameter Tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxdaPLKCGRsD",
    "outputId": "3525388f-6927-4dfd-b689-e8186bc7a8d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best CV ROC AUC: 0.7947701967775918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'],      # Regularization norms\n",
    "    'solver': ['liblinear']       # Supports both l1 and l2 penalties\n",
    "}\n",
    "\n",
    "logreg = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best CV ROC AUC:\", grid_search.best_score_)\n",
    "\n",
    "best_logreg = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-MFt5-cHQjp"
   },
   "source": [
    " Evaluate the Tuned Logistic Regression on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MT2f_3SkGUZs",
    "outputId": "6d18fe3d-77f0-45ed-ef71-56e2e775c625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation (Logistic Regression):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.59      0.73     45139\n",
      "           1       0.19      0.74      0.30      5931\n",
      "\n",
      "    accuracy                           0.61     51070\n",
      "   macro avg       0.57      0.66      0.52     51070\n",
      "weighted avg       0.86      0.61      0.68     51070\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26616 18523]\n",
      " [ 1542  4389]]\n",
      "ROC AUC: 0.7319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "best_lr = grid_search.best_estimator_\n",
    "\n",
    "def evaluate_final(model, X_test, y_test, threshold=0.4):\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    print(\"Test Set Evaluation (Logistic Regression):\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "\n",
    "evaluate_final(best_lr, X_test, y_test, threshold=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsC57L-qHWpK"
   },
   "source": [
    "Train, Evaluate, and Compare Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCSMXtn5HTVm",
    "outputId": "f8def2c3-d181-40c5-93ca-9c722569a230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9028/9028 - 15s - 2ms/step - accuracy: 0.7264 - auc: 0.7807 - loss: 0.5402 - val_accuracy: 0.6018 - val_auc: 0.0000e+00 - val_loss: 0.6699\n",
      "Epoch 2/10\n",
      "9028/9028 - 14s - 2ms/step - accuracy: 0.7341 - auc: 0.7912 - loss: 0.5303 - val_accuracy: 0.6052 - val_auc: 0.0000e+00 - val_loss: 0.6746\n",
      "Epoch 3/10\n",
      "9028/9028 - 21s - 2ms/step - accuracy: 0.7355 - auc: 0.7933 - loss: 0.5279 - val_accuracy: 0.6152 - val_auc: 0.0000e+00 - val_loss: 0.6716\n",
      "Epoch 4/10\n",
      "9028/9028 - 14s - 2ms/step - accuracy: 0.7367 - auc: 0.7945 - loss: 0.5269 - val_accuracy: 0.6016 - val_auc: 0.0000e+00 - val_loss: 0.6907\n",
      "Epoch 5/10\n",
      "9028/9028 - 14s - 2ms/step - accuracy: 0.7371 - auc: 0.7955 - loss: 0.5256 - val_accuracy: 0.5818 - val_auc: 0.0000e+00 - val_loss: 0.7090\n",
      "Epoch 6/10\n",
      "9028/9028 - 14s - 2ms/step - accuracy: 0.7367 - auc: 0.7959 - loss: 0.5254 - val_accuracy: 0.5839 - val_auc: 0.0000e+00 - val_loss: 0.7132\n",
      "Epoch 7/10\n",
      "9028/9028 - 14s - 2ms/step - accuracy: 0.7380 - auc: 0.7967 - loss: 0.5245 - val_accuracy: 0.5783 - val_auc: 0.0000e+00 - val_loss: 0.7243\n",
      "Epoch 8/10\n",
      "9028/9028 - 14s - 2ms/step - accuracy: 0.7378 - auc: 0.7969 - loss: 0.5243 - val_accuracy: 0.5871 - val_auc: 0.0000e+00 - val_loss: 0.7129\n",
      "Epoch 9/10\n",
      "9028/9028 - 23s - 3ms/step - accuracy: 0.7378 - auc: 0.7971 - loss: 0.5241 - val_accuracy: 0.5785 - val_auc: 0.0000e+00 - val_loss: 0.7236\n",
      "Epoch 10/10\n",
      "9028/9028 - 14s - 2ms/step - accuracy: 0.7377 - auc: 0.7979 - loss: 0.5233 - val_accuracy: 0.5952 - val_auc: 0.0000e+00 - val_loss: 0.6920\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step\n",
      "DL Model - Accuracy: 0.7162, ROC AUC: 0.7375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.82     45139\n",
      "           1       0.23      0.62      0.34      5931\n",
      "\n",
      "    accuracy                           0.72     51070\n",
      "   macro avg       0.58      0.67      0.58     51070\n",
      "weighted avg       0.85      0.72      0.76     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "dl_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_res.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "dl_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "dl_model.fit(X_train_res, y_train_res,\n",
    "             validation_split=0.2,\n",
    "             epochs=10,\n",
    "             batch_size=32,\n",
    "             verbose=2)\n",
    "\n",
    "# Evaluate DL model on test set\n",
    "dl_pred_prob = dl_model.predict(X_test).ravel()\n",
    "dl_pred = (dl_pred_prob >= 0.4).astype(int)\n",
    "dl_accuracy = (dl_pred == y_test).mean()\n",
    "dl_auc = roc_auc_score(y_test, dl_pred_prob)\n",
    "print(f\"DL Model - Accuracy: {dl_accuracy:.4f}, ROC AUC: {dl_auc:.4f}\")\n",
    "print(classification_report(y_test, dl_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhFiqIHDIj03"
   },
   "source": [
    "Model Performance Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFdaUA7oImD6",
    "outputId": "d7d3cbd6-c9a7-4ef5-f27c-ba66a6b4f40a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step\n",
      "                 Model   ROC AUC  Recall (Default)  Precision (Default)\n",
      "0  Logistic Regression  0.731903           0.74001             0.191559\n",
      "1        Deep Learning  0.737472           0.62030             0.231078\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.59      0.73     45139\n",
      "           1       0.19      0.74      0.30      5931\n",
      "\n",
      "    accuracy                           0.61     51070\n",
      "   macro avg       0.57      0.66      0.52     51070\n",
      "weighted avg       0.86      0.61      0.68     51070\n",
      "\n",
      "Deep Learning Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.82     45139\n",
      "           1       0.23      0.62      0.34      5931\n",
      "\n",
      "    accuracy                           0.72     51070\n",
      "   macro avg       0.58      0.67      0.58     51070\n",
      "weighted avg       0.85      0.72      0.76     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, classification_report\n",
    "\n",
    "# Step 1: Calculate probabilities and binary predictions for logistic regression\n",
    "y_prob_lr = best_lr.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.4\n",
    "y_pred_lr = (y_prob_lr >= threshold).astype(int)\n",
    "\n",
    "# Step 2: Calculate similarly for deep learning model (assuming defined as dl_model)\n",
    "y_prob_dl = dl_model.predict(X_test).ravel()\n",
    "y_pred_dl = (y_prob_dl >= threshold).astype(int)\n",
    "\n",
    "# Step 3: Compute metrics for logistic regression\n",
    "lr_recall = recall_score(y_test, y_pred_lr)\n",
    "lr_precision = precision_score(y_test, y_pred_lr)\n",
    "lr_auc = roc_auc_score(y_test, y_prob_lr)\n",
    "\n",
    "# Step 4: Compute metrics for deep learning\n",
    "dl_recall = recall_score(y_test, y_pred_dl)\n",
    "dl_precision = precision_score(y_test, y_pred_dl)\n",
    "dl_auc = roc_auc_score(y_test, y_prob_dl)\n",
    "\n",
    "# Step 5: Create comparison dataframe\n",
    "import pandas as pd\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"Deep Learning\"],\n",
    "    \"ROC AUC\": [lr_auc, dl_auc],\n",
    "    \"Recall (Default)\": [lr_recall, dl_recall],\n",
    "    \"Precision (Default)\": [lr_precision, dl_precision]\n",
    "})\n",
    "\n",
    "print(comparison_df)\n",
    "\n",
    "# Optional: Print classification reports for detailed insights\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "print(\"Deep Learning Classification Report:\\n\", classification_report(y_test, y_pred_dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "JNipq_8-HZLH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tW3xJP2KIiF1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
